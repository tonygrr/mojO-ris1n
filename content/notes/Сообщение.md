---
title: "Сообщение"
date: 2022.03.25
time: 16:23
aliases: [сообщения]
tags: [цос]
---

# Сообщение

- **Сообщение** — информация, представленная в форме, которая позволяет осуществить ее преобразования с целью передачи и обработки[^1]. 

## Классификация сообщений

- Дискретные;
- Непрерывные.

### Дискретные сообщения

- **Дискретные сообщения** – это последовательность из конечного числа элементов, которые называются символами.
	- Примеры дискретных сообщений: 37439 или 101110. В первом примере алфавит состоит из десяти символов, а во втором – из двух.

### Непрерывные сообщения

- Непрерывные сообщения и их параметры сигналов (информационные параметры) являются непрерывными функциями времени.

### Связь цифровых и дискретных сообщений

- Непрерывное сообщение может быть преобразовано в дискретное путем его квантования по уровню и дискретизации по времени соответствующего информационного параметра сигнала.
	- При дискретизации по времени выбираются значения информационного параметра в заранее определенные дискретные моменты времени, а при квантовании по уровню выбранные значения округляются до некоторых (заранее определенных) дискретных величин.
		- Эти величины можно записать в виде дискретных сообщений. 
			- Полученные числа, в свою очередь, могут быть отображены новым сигналом — цифровым сигналом[^3].

## Характеристики сообщения

- **Сигнал** — физическая величина, параметры которого и характеризуют сообщение[^2]. 
- **Длина сообщения** — кол-во *символов* в сообщении.
	- **Алфавит** — полный набор *символов*.
		- **Основание системы счисления** — объём алфавита.
- **Количество информации**, получаемое при передаче сообщения (далее об этом более подробно).

### Количество информации

- #формула: $x_i$: $J_i=-log_2{p(x_i)}$.

### Энтропия

- **Энтропия** — среднее *количество информации*, получаемое от источника при передаче одного символа сообщения.
	- #формула: $H\left(X_{0}\right)=\sum_{i=1}^{N} p\left(x_{i}\right) J_{i}=-\sum_{i=1}^{N} p\left(x_{i}\right) log_{2} p\left(x_{i}\right)$;
		- #еи: бит.
	- Она характеризует производительность источника и определяется распределением вероятностей передаваемых букв.
	- **Аддитивная мера Хартли** — ёмкость источника сообщения из $N$ независимых символов (максимальное значение энтропии).
		- #формула: $J=log_2{N}$;
		- определяется структурой сообщений: если они имеют длину $n$ и образуются из алфавита основания $m,$ то их число $N=m^n$ и $J=nlog_2{m}$.

### Избыточность

- **Избыточность** — величина, показывающая, какая часть информации (в битах на одну букву сообщения) оказывается «лишней» из-за неравномерной априорной вероятности их появления.
	- Классификация:
		- **Абсолютная избыточность**
			- #формула: $D_a = H(X_0)-J$.
		- **Относительная избыточность**
			- #формула: $D_a = H(X_0)-J$.

[^1]: [“Экономное кодирование дискретных сообщений”, p. 3](zotero://select/library/items/LHQHZWCC), [pdf](zotero://open-pdf/library/items/XFRZTZU2?page=3&annotation=PAMCLLRF)
[^2]: [“Экономное кодирование дискретных сообщений”, p. 3](zotero://select/library/items/LHQHZWCC), [pdf](zotero://open-pdf/library/items/XFRZTZU2?page=3&annotation=977XJWY7)
[^3]: [“Экономное кодирование дискретных сообщений”, p. 3](zotero://select/library/items/LHQHZWCC), [pdf](zotero://open-pdf/library/items/XFRZTZU2?page=3&annotation=H9PA6T7Q)